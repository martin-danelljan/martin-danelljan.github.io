
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":["leike"],"categories":null,"content":"Go to Lei’s personal webpage\n","date":1680336000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1680336000,"objectID":"1c5aeb2b4c7c3d1c4ff085b442f83653","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Go to Lei’s personal webpage","tags":null,"title":"Lei Ke","type":"authors"},{"authors":null,"categories":null,"content":"I am a research group leader at ETH Zurich. I received my Ph.D. degree from Linköping University, Sweden in 2018. My thesis “Visual Tracking” was awarded the biennial Best Nordic Thesis Prize. My main research interests are temporal perception, deep probabilistic models, and generative methods. My research includes applications to video tracking and segmentation, dense correspondence estimation, image enhancement, and much more.\nNews:\nThree CVPR 2023 papers accepted. 2 TPAMI papers accepted. Six ECCV 2022 papers accepted. ","date":1680336000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1680336000,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a research group leader at ETH Zurich. I received my Ph.D. degree from Linköping University, Sweden in 2018. My thesis “Visual Tracking” was awarded the biennial Best Nordic Thesis Prize.","tags":null,"title":"Martin Danelljan","type":"authors"},{"authors":["siyuan"],"categories":null,"content":"Go to Siyuan’s personal webpage\n","date":1680325200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1680325200,"objectID":"4b1f0855ea6c85c0bbe31aae1bb0283c","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Go to Siyuan’s personal webpage","tags":null,"title":"Siyuan Li","type":"authors"},{"authors":["prune"],"categories":null,"content":"Go to Prune’s personal webpage\n","date":1677974400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1677974400,"objectID":"dfa774c23ba821acbb08dab15217ba6e","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Go to Prune’s personal webpage","tags":null,"title":"Prune Truong","type":"authors"},{"authors":["christoph"],"categories":null,"content":"Go to Christoph’s personal webpage\n","date":1659340800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1659340800,"objectID":"abe9ff028415a6821a3c868ca2b6f435","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Go to Christoph’s personal webpage","tags":null,"title":"Christoph Mayer","type":"authors"},{"authors":["joakim"],"categories":null,"content":"Go to Joakim’s github page\n","date":1659340800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1659340800,"objectID":"89f1624d276925611f97b1a2e6d8ef50","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Go to Joakim’s github page","tags":null,"title":"Joakim Johnander","type":"authors"},{"authors":["matthieu"],"categories":null,"content":"Go to Matthieu’s personal webpage ","date":1659340800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1659340800,"objectID":"281fe212df01b8a85afd8fc7f1b7f9d0","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Go to Matthieu’s personal webpage ","tags":null,"title":"Matthieu Paul","type":"authors"},{"authors":["ardhendu"],"categories":null,"content":"Go to Ardhendu’s personal webpage\n","date":1659337200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1659337200,"objectID":"29bfc4045551e68cd72df4bfd67411a2","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Go to Ardhendu’s personal webpage","tags":null,"title":"Ardhendu Tripathi","type":"authors"},{"authors":["andreasl"],"categories":null,"content":"Go to Andreas’s twitter\n","date":1646121600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1646121600,"objectID":"2445f48a0ad8edc70f9397aa9d0f9891","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Go to Andreas’s twitter","tags":null,"title":"Andreas Lugmayr","type":"authors"},{"authors":["nico"],"categories":null,"content":"","date":1646110800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1646110800,"objectID":"eceb09896bb9761ffd0d3445c2c97068","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Jan-Nico Zäch","type":"authors"},{"authors":["goutam"],"categories":null,"content":"Go to Goutam’s personal webpage\n","date":1646103600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1646103600,"objectID":"59a9864dcfce8c2218e781c0e1a8b643","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Go to Goutam’s personal webpage","tags":null,"title":"Goutam Bhat","type":"authors"},{"authors":["evan"],"categories":null,"content":"","date":1646092800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1646092800,"objectID":"e5f4b938f892e983a95e1da005cd4762","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Evangelos Ntavelis","type":"authors"},{"authors":["mo"],"categories":null,"content":"Go to Mohamad’s personal webpage\n","date":1646092800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1646092800,"objectID":"d47a788ced3aa36cbc086754aed4e875","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Go to Mohamad’s personal webpage","tags":null,"title":"Mohamad Shahbazi","type":"authors"},{"authors":["fredrik"],"categories":null,"content":"Go to Fredrik’s personal webpage\n","date":1599696000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1599696000,"objectID":"49598eaa23b3c56be43089d1f63e312e","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Go to Fredrik’s personal webpage","tags":null,"title":"Fredrik Gustafsson","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://martin-danelljan.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Lei Ke","Martin Danelljan","Henghui Ding","Yu-Wing Tai","Chi-Keung Tang","Fisher Yu"],"categories":null,"content":"","date":1680336000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680336000,"objectID":"3c747e3aa37fded54483e36fd4d9c6eb","permalink":"https://martin-danelljan.github.io/publication/maskfreevis/","publishdate":"2023-04-01T08:00:00Z","relpermalink":"/publication/maskfreevis/","section":"publication","summary":"CVPR 2023\nState-of-the-art Video Instance Segmentation without any ground-truth masks for training.","tags":null,"title":"Mask-Free Video Instance Segmentation","type":"publication"},{"authors":["Siyuan Li","Tobias Fischer","Lei Ke","Henghui Ding","Martin Danelljan","Fisher Yu"],"categories":null,"content":"","date":1680325200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680325200,"objectID":"23e3a45a226cb0e4c809bb494edc54dc","permalink":"https://martin-danelljan.github.io/publication/ovtrack/","publishdate":"2023-04-01T05:00:00Z","relpermalink":"/publication/ovtrack/","section":"publication","summary":"CVPR 2023\nFirst method and benchmark for open vocabulary tracking.","tags":null,"title":"OVTrack: Open-Vocabulary Multiple Object Tracking","type":"publication"},{"authors":["Rui Gong","Qin Wang","Martin Danelljan","Dengxin Dai","Luc Van Gool"],"categories":null,"content":"","date":1680314400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680314400,"objectID":"039f78c9241ad78f45fd9510016f5532","permalink":"https://martin-danelljan.github.io/publication/cprda/","publishdate":"2023-04-01T02:00:00Z","relpermalink":"/publication/cprda/","section":"publication","summary":"CVPR 2023\nLeveraging implicit models to estimate the output confidence for unsupervised domain adaptation.","tags":null,"title":"Continuous Pseudo-Label Rectified Domain Adaptive Semantic Segmentation with Implicit Neural Representations","type":"publication"},{"authors":["Prune Truong","Martin Danelljan","Luc Van Gool","Radu Timofte"],"categories":null,"content":"","date":1677974400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677974400,"objectID":"4e2bd043fa62666010c0e4c914d006b1","permalink":"https://martin-danelljan.github.io/publication/pdcnetplus/","publishdate":"2023-03-05T00:00:00Z","relpermalink":"/publication/pdcnetplus/","section":"publication","summary":"TPAMI 2023\nA method that gives you accurate dense optical flow and correspondences with robust uncertainty.","tags":null,"title":"PDC-Net+: Enhanced Probabilistic Dense Correspondence Network","type":"publication"},{"authors":["Sajid Javed","Martin Danelljan","Fahad Shahbaz Khan","Muhammad Haris Khan","Michael Felsberg","Jiri Matas"],"categories":null,"content":"","date":1675555200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675555200,"objectID":"0e3310503614666caae46dd2ca2b590e","permalink":"https://martin-danelljan.github.io/publication/trsurv/","publishdate":"2023-02-05T00:00:00Z","relpermalink":"/publication/trsurv/","section":"publication","summary":"TPAMI 2023\nComprehensive survey over Visual Object Tracking.","tags":null,"title":"Visual Object Tracking with Discriminative Filters and Siamese Networks: A Survey and Outlook","type":"publication"},{"authors":["Joakim Johnander","Johan Edstedt","Michael Felsberg","Fahad Shahbaz Khan","Martin Danelljan"],"categories":null,"content":"","date":1659340800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659340800,"objectID":"62f7066957eec9f3d225d65769f12973","permalink":"https://martin-danelljan.github.io/publication/gpfss/","publishdate":"2022-08-01T08:00:00Z","relpermalink":"/publication/gpfss/","section":"publication","summary":"ECCV 2022\nA few-shot learner based on Gaussian Processes for few-shot semantic segmentation.","tags":null,"title":"Dense Gaussian Processes for Few-Shot Segmentation","type":"publication"},{"authors":["Matthieu Paul","Martin Danelljan","Christoph Mayer","Luc Van Gool"],"categories":null,"content":"","date":1659340800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659340800,"objectID":"a1af82f9fd53c1bfd387add56e074f0d","permalink":"https://martin-danelljan.github.io/publication/rts/","publishdate":"2022-08-01T08:00:00Z","relpermalink":"/publication/rts/","section":"publication","summary":"ECCV 2022\nBringing the robustness in tracking to video segmentation.","tags":null,"title":"Robust Visual Tracking by Segmentation","type":"publication"},{"authors":["Ardhendu Tripathi","Martin Danelljan","Samarth Shukla","Radu Timofte","Luc Van Gool"],"categories":null,"content":"","date":1659337200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659337200,"objectID":"32a04fe03c55058ee248d0a196db0c09","permalink":"https://martin-danelljan.github.io/publication/trisp/","publishdate":"2022-08-01T07:00:00Z","relpermalink":"/publication/trisp/","section":"publication","summary":"ECCV 2022\nA method and dataset for learning the camera ISP in the wild.","tags":null,"title":"Transform your Smartphone into a DSLR Camera: Learning the ISP in the Wild","type":"publication"},{"authors":["Siyuan Li","Martin Danelljan","Henghui Ding","Thomas Huang","Fisher Yu"],"categories":null,"content":"","date":1659330000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659330000,"objectID":"93e854027a7fcfe7fbae41ab783ee248","permalink":"https://martin-danelljan.github.io/publication/tetr/","publishdate":"2022-08-01T05:00:00Z","relpermalink":"/publication/tetr/","section":"publication","summary":"ECCV 2022\nA new method and metric for large-scale and open world multi-object tracking.","tags":null,"title":"Tracking Every Thing in the Wild","type":"publication"},{"authors":["Lei Ke","Henghui Ding","Martin Danelljan","Yu-Wing Tai","Chi-Keung Tang","Fisher Yu"],"categories":null,"content":"","date":1659326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659326400,"objectID":"84f8f191b5e5ba28c0c668db0056f3d0","permalink":"https://martin-danelljan.github.io/publication/vidmasktr/","publishdate":"2022-08-01T04:00:00Z","relpermalink":"/publication/vidmasktr/","section":"publication","summary":"ECCV 2022\nAn efficient transformer-based method for highly accurate video instance segmentation.","tags":null,"title":"Video Mask Transfiner for High-Quality Video Instance Segmentation","type":"publication"},{"authors":["Rui Gong","Martin Danelljan","Dengxin Dai","Danda Pani Paudel","Ajad Chhatkuli","Fisher Yu","Luc Van Gool"],"categories":null,"content":"","date":1659315600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659315600,"objectID":"683e4580c66e888ece8f63e0baa3efcb","permalink":"https://martin-danelljan.github.io/publication/tacs/","publishdate":"2022-08-01T01:00:00Z","relpermalink":"/publication/tacs/","section":"publication","summary":"ECCV 2022\nBringing the robustness in tracking to video segmentation.","tags":null,"title":"TACS: Taxonomy Adaptive Cross-Domain Semantic Segmentation","type":"publication"},{"authors":["Andreas Lugmayr","Martin Danelljan","Andres Romero","Fisher Yu","Radu Timofte","Luc Van Gool"],"categories":null,"content":"","date":1646121600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646121600,"objectID":"2fc916786f1e2ef2532112794d92787e","permalink":"https://martin-danelljan.github.io/publication/repaint/","publishdate":"2022-03-01T08:00:00Z","relpermalink":"/publication/repaint/","section":"publication","summary":"CVPR 2022\nA Probabilistic Denoising Diffusion Model for image inpainting.","tags":null,"title":"RePaint: Inpainting using Denoising Diffusion Probabilistic Models","type":"publication"},{"authors":["Lei Ke","Martin Danelljan","Xia Li","Yu-Wing Tai","Chi-Keung Tang","Fisher Yu"],"categories":null,"content":"","date":1646118000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646118000,"objectID":"7672c1e0f4fe3c6c78ced3803f8f5154","permalink":"https://martin-danelljan.github.io/publication/masktr/","publishdate":"2022-03-01T07:00:00Z","relpermalink":"/publication/masktr/","section":"publication","summary":"CVPR 2022\nAn efficient transformer-based method for highly accurate instance segmentation.","tags":null,"title":"Mask Transfiner for High-Quality Instance Segmentation","type":"publication"},{"authors":["Prune Truong","Martin Danelljan","Fisher Yu","Luc Van Gool"],"categories":null,"content":"","date":1646114400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646114400,"objectID":"1304b259cbcb964d6040c860a19196b4","permalink":"https://martin-danelljan.github.io/publication/pwarpc/","publishdate":"2022-03-01T06:00:00Z","relpermalink":"/publication/pwarpc/","section":"publication","summary":"CVPR 2022\nA weakly-supervised method for learning dense semantic correspondences.","tags":null,"title":"Probabilistic Warp Consistency for Weakly-Supervised Semantic Correspondences","type":"publication"},{"authors":["Jan-Nico Zäch","Alexander Liniger","Martin Danelljan","Dengxin Dai","Luc Van Gool"],"categories":null,"content":"","date":1646110800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646110800,"objectID":"bcfce1464a74d5aea8a59ffd363ec957","permalink":"https://martin-danelljan.github.io/publication/aqctrack/","publishdate":"2022-03-01T05:00:00Z","relpermalink":"/publication/aqctrack/","section":"publication","summary":"CVPR 2022\nA Multi-Object Tracking algorithm that can be solved with Adiabatic Quantum Computing","tags":null,"title":"Adiabatic Quantum Computing for Multi Object Tracking","type":"publication"},{"authors":["Christoph Mayer","Martin Danelljan","Goutam Bhat","Matthieu Paul","Danda Pani Paudel","Fisher Yu","Luc Van Gool"],"categories":null,"content":"","date":1646103600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646103600,"objectID":"751e12410dbd2c9f3b6f6bebe900677d","permalink":"https://martin-danelljan.github.io/publication/tmp/","publishdate":"2022-03-01T03:00:00Z","relpermalink":"/publication/tmp/","section":"publication","summary":"CVPR 2022\nA transformer-based tracker inspired by discriminative correlation filters.","tags":null,"title":"Transforming Model Prediction for Tracking","type":"publication"},{"authors":["Evangelos Ntavelis","Mohamad Shahbazi","Iason Kastanis","Radu Timofte","Martin Danelljan","Luc Van Gool"],"categories":null,"content":"","date":1646092800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646092800,"objectID":"7b1540c926f51a7dc49ab830773f5a53","permalink":"https://martin-danelljan.github.io/publication/scaleparty/","publishdate":"2022-03-01T00:00:00Z","relpermalink":"/publication/scaleparty/","section":"publication","summary":"CVPR 2022\nA GAN that generates consistent images at arbitrary scales and resolutions.","tags":null,"title":"Arbitrary-Scale Image Synthesis","type":"publication"},{"authors":["Mohamad Shahbazi","Martin Danelljan","Danda Pani Paudel","Luc Van Gool"],"categories":null,"content":"","date":1643684400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643684400,"objectID":"19305814792a0d2a5b79872824213d55","permalink":"https://martin-danelljan.github.io/publication/colcondgan/","publishdate":"2022-02-01T03:00:00Z","relpermalink":"/publication/colcondgan/","section":"publication","summary":"ICLR 2022\nAnalyzing and addressing mode collapse in conditional GANs caused by the conditioning itself.","tags":null,"title":"Collapse by Conditioning: Training Class-conditional GANs with Limited Data","type":"publication"},{"authors":["Jan-Nico Zäch","Dengxin Dai","Alexander Liniger","Martin Danelljan","Luc Van Gool"],"categories":null,"content":"","date":1642222800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642222800,"objectID":"32b5b80fe854503b040e2195e9d4c6a2","permalink":"https://martin-danelljan.github.io/publication/graph3dtrack/","publishdate":"2022-01-15T05:00:00Z","relpermalink":"/publication/graph3dtrack/","section":"publication","summary":"ICRA 2022\nAn online 3D Multi-Object Tracking method based on graph neural networks.","tags":null,"title":"Learnable Online Graph Representations for 3D Multi-Object Tracking","type":"publication"},{"authors":["Lei Ke","Xia Li","Martin Danelljan","Yu-Wing Tai","Chi-Keung Tang","Fisher Yu"],"categories":null,"content":"","date":1632700800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632700800,"objectID":"2ac72c95e1aa5a715db146ff244d0657","permalink":"https://martin-danelljan.github.io/publication/pcan/","publishdate":"2021-09-27T00:00:00Z","relpermalink":"/publication/pcan/","section":"publication","summary":"NeurIPS 2021 Spotlight\nEfficient cross-attention for video instance segmentation.","tags":null,"title":"Prototypical Cross-Attention Networks for Multiple Object Tracking and Segmentation","type":"publication"},{"authors":["Prune Truong","Martin Danelljan","Fisher Yu","Luc Van Gool"],"categories":null,"content":"","date":1627797600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627797600,"objectID":"589e7411bb64f8e505ea5b2df4bc25ee","permalink":"https://martin-danelljan.github.io/publication/warpc/","publishdate":"2021-08-01T06:00:00Z","relpermalink":"/publication/warpc/","section":"publication","summary":"ICCV 2021 Oral\nUnsupervised method for learning dense correspondences and optical flow on real image pairs.","tags":null,"title":"Warp Consistency for Unsupervised Learning of Dense Correspondences","type":"publication"},{"authors":["Goutam Bhat","Martin Danelljan","Fisher Yu","Luc Van Gool","Radu Timofte"],"categories":null,"content":"","date":1627794000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627794000,"objectID":"1340be846a0fee2e116324d04c19571e","permalink":"https://martin-danelljan.github.io/publication/deepreparam/","publishdate":"2021-08-01T05:00:00Z","relpermalink":"/publication/deepreparam/","section":"publication","summary":"ICCV 2021 Oral\nDeep optimization-based formulation for multi-frame super-resolution and denoising.","tags":null,"title":"Deep Reparametrization of Multi-Frame Super-Resolution and Denoising","type":"publication"},{"authors":["Bin Zhao","Goutam Bhat","Martin Danelljan","Luc Van Gool","Radu Timofte"],"categories":null,"content":"","date":1627790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627790400,"objectID":"ce8a9a511cacf4bb9575d39d6a60fc6d","permalink":"https://martin-danelljan.github.io/publication/vidboxseg/","publishdate":"2021-08-01T04:00:00Z","relpermalink":"/publication/vidboxseg/","section":"publication","summary":"ICCV 2021\nAn optimization-based architecture for converting video bounding box annotations to segmentation masks.","tags":null,"title":"Generating Masks from Boxes by Mining Spatio-Temporal Consistencies in Videos","type":"publication"},{"authors":["Christoph Mayer","Martin Danelljan","Danda Pani Paudel","Luc Van Gool"],"categories":null,"content":"","date":1627786800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627786800,"objectID":"95f23ae8761ca94cfcfc02ad4e823cb8","permalink":"https://martin-danelljan.github.io/publication/keeptrack/","publishdate":"2021-08-01T03:00:00Z","relpermalink":"/publication/keeptrack/","section":"publication","summary":"ICCV 2021\nAssociating the target and distractor objects for robust visual tracking.","tags":null,"title":"Learning Target Candidate Association to Keep Track of What Not to Track","type":"publication"},{"authors":["Jingyun Liang","Andreas Lugmayr","Kai Zhang","Martin Danelljan","Luc Van Gool","Radu Timofte"],"categories":null,"content":"","date":1627779600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627779600,"objectID":"2ab4212cb853d037b3b85968e3399aaa","permalink":"https://martin-danelljan.github.io/publication/hcflow/","publishdate":"2021-08-01T01:00:00Z","relpermalink":"/publication/hcflow/","section":"publication","summary":"ICCV 2021\nA unified hierarchical normalizing flow architecture for super-resolution and image rescaling.","tags":null,"title":"Hierarchical Conditional Flow: A Unified Framework for Image Super-Resolution and Image Rescaling","type":"publication"},{"authors":["Shipra Jain","Danda Pani Paudel","Martin Danelljan","Luc Van Gool"],"categories":null,"content":"","date":1627776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627776000,"objectID":"427685771ed4ea3b7fc0759d1d6b72ea","permalink":"https://martin-danelljan.github.io/publication/scalingseg/","publishdate":"2021-08-01T00:00:00Z","relpermalink":"/publication/scalingseg/","section":"publication","summary":"ICCV 2021\nReducing memory complexity for training semantic segmentation models with large number of classes.","tags":null,"title":"Scaling Semantic Segmentation Beyond 1K Classes on a Single GPU","type":"publication"},{"authors":["Matthieu Paul","Martin Danelljan","Luc Van Gool","Radu Timofte"],"categories":null,"content":"","date":1625108400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625108400,"objectID":"cac82bb59870422fb9396f46150a2187","permalink":"https://martin-danelljan.github.io/publication/locattseg/","publishdate":"2021-07-01T03:00:00Z","relpermalink":"/publication/locattseg/","section":"publication","summary":"IROS 2021\nA local memory cross-attention module for fast video semantic segmentation.","tags":null,"title":"Local Memory Attention for Fast Video Semantic Segmentation","type":"publication"},{"authors":["Prune Truong","Martin Danelljan","Luc Van Gool","Radu Timofte"],"categories":null,"content":"","date":1614902400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614902400,"objectID":"e2c9714f1c9568dd805645ebb875177c","permalink":"https://martin-danelljan.github.io/publication/pdcnet/","publishdate":"2021-03-05T00:00:00Z","relpermalink":"/publication/pdcnet/","section":"publication","summary":"CVPR 2021 Oral\nA method that gives you accurate dense optical flow and correspondences with robust uncertainty.","tags":null,"title":"Learning Accurate Dense Correspondences and When to Trust Them","type":"publication"},{"authors":["Valentin Wolf","Andreas Lugmayr","Martin Danelljan","Luc Van Gool","Radu Timofte"],"categories":null,"content":"","date":1614816000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614816000,"objectID":"51c8aa561c94ea9ae44ba6a03e97cde5","permalink":"https://martin-danelljan.github.io/publication/deflow/","publishdate":"2021-03-04T00:00:00Z","relpermalink":"/publication/deflow/","section":"publication","summary":"CVPR 2021 Oral\nA novel unpaired learning formulation for conditional normalizing flows with applications to learning image degradations.","tags":null,"title":"DeFlow: Learning Complex Image Degradations from Unpaired Data with Conditional Flows","type":"publication"},{"authors":["Goutam Bhat","Martin Danelljan","Luc Van Gool","Radu Timofte"],"categories":null,"content":"","date":1614729600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614729600,"objectID":"ff3c6b7a2e75dfbe931216a2652502a0","permalink":"https://martin-danelljan.github.io/publication/burstsr/","publishdate":"2021-03-03T00:00:00Z","relpermalink":"/publication/burstsr/","section":"publication","summary":"CVPR 2021\nAn attention based architecture and real-world dataset for burst super-resolution.","tags":null,"title":"Deep Burst Super-Resolution","type":"publication"},{"authors":["Yawei Li","Wen Li","Martin Danelljan","Kai Zhang","Shuhang Gu","Luc Van Gool","Radu Timofte"],"categories":null,"content":"","date":1614643200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614643200,"objectID":"67db2d49815ce7b6dc9f26e7f0ca6caf","permalink":"https://martin-danelljan.github.io/publication/hethyp/","publishdate":"2021-03-02T00:00:00Z","relpermalink":"/publication/hethyp/","section":"publication","summary":"CVPR 2021\nWe tackle the problem of convolutional neural network design by adjusting the channel configurations of predefined networks.","tags":null,"title":"The Heterogeneity Hypothesis: Finding Layer-Wise Dissimilated Network Architecture","type":"publication"},{"authors":["Ardhendu Tripathi","Martin Danelljan","Luc Van Gool","Radu Timofte"],"categories":null,"content":"","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"234a44155c3e1e5d8a653d9546887e23","permalink":"https://martin-danelljan.github.io/publication/fiml/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/publication/fiml/","section":"publication","summary":"ICRA 2021\nAn optimization-based meta-learning approach for few-shot classification.","tags":null,"title":"Few-Shot Classification By Few-Iteration Meta-Learning","type":"publication"},{"authors":["Martin Danelljan","吳恩達"],"categories":["Demo","教程"],"content":"import libr print(\u0026#39;hello\u0026#39;) Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It’s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more Get Started 👉 Create a new site 📚 Personalize your site 💬 Chat with the Wowchemy community or Hugo community 🐦 Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy 💡 Request a feature or report a bug for Wowchemy ⬆️ Updating Wowchemy? View the Update Tutorial and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n❤️ Click here to become a sponsor and help support Wowchemy’s future ❤️ As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features 🦄✨\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you’ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://martin-danelljan.github.io/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome 👋 We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","开源"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":["Alexandre Carlier","Martin Danelljan","Alexandre Alahi","Radu Timofte"],"categories":null,"content":"","date":1601510400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601510400,"objectID":"aa0643f9ae371968a90564ff91f0a6d0","permalink":"https://martin-danelljan.github.io/publication/deepsvg/","publishdate":"2020-10-01T00:00:00Z","relpermalink":"/publication/deepsvg/","section":"publication","summary":"NeurIPS 2020\nDataset and method for generating vector graphics.","tags":null,"title":"DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation","type":"publication"},{"authors":["Prune Truong","Martin Danelljan","Luc Van Gool","Radu Timofte"],"categories":null,"content":"","date":1601510400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601510400,"objectID":"0d940fbc9094673c4bc765b9349a1834","permalink":"https://martin-danelljan.github.io/publication/gocor/","publishdate":"2020-10-01T00:00:00Z","relpermalink":"/publication/gocor/","section":"publication","summary":"NeurIPS 2020\nA fully differentiable dense matching module for your correspondence or optical flow network.","tags":null,"title":"GOCor: Bringing Globally Optimized Correspondence Volumes into Your Neural Network","type":"publication"},{"authors":["Fredrik Gustafsson","Martin Danelljan","Radu Timofte","Thomas Schön"],"categories":null,"content":"","date":1599696000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599696000,"objectID":"243dbe1024dc6b019c68a658f6e80fdb","permalink":"https://martin-danelljan.github.io/publication/ebmregtr/","publishdate":"2020-09-10T00:00:00Z","relpermalink":"/publication/ebmregtr/","section":"publication","summary":"BMVC 2020 Investigating how to train a deep energy-based model for accurate regression.","tags":null,"title":"How to Train Your Energy-Based Model for Regression","type":"publication"},{"authors":["Goutam Bhat","Felix Järemo Lawin","Martin Danelljan","Andreas Robinson","Michael Felsberg","Luc Van Gool","Radu Timofte"],"categories":null,"content":"","date":1598313600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598313600,"objectID":"96e076ae4e4b228bedd992f6bd9e8f9f","permalink":"https://martin-danelljan.github.io/publication/lwtl/","publishdate":"2020-08-25T00:00:00Z","relpermalink":"/publication/lwtl/","section":"publication","summary":"ECCV 2020 Oral\nAn optimization-based few-shot learner for VOS.","tags":null,"title":"Learning What to Learn for Video Object Segmentation","type":"publication"},{"authors":["Andreas Lugmayr","Martin Danelljan","Luc Van Gool","Radu Timofte"],"categories":null,"content":"","date":1598227200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598227200,"objectID":"1d78c4f88dd9f6f0f824f495c284dcfa","permalink":"https://martin-danelljan.github.io/publication/srflow/","publishdate":"2020-08-24T00:00:00Z","relpermalink":"/publication/srflow/","section":"publication","summary":"ECCV 2020 Spotlight\nNormalizing flow based super-resolution method capable of learning the conditional distribution of the output given the low-resolution input.","tags":null,"title":"SRFlow: Learning the Super-Resolution Space with Normalizing Flow","type":"publication"},{"authors":["Fredrik Gustafsson","Martin Danelljan","Goutam Bhat","Thomas Schön"],"categories":null,"content":"","date":1598054400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598054400,"objectID":"96f7685f8a566cebe831e239dade668c","permalink":"https://martin-danelljan.github.io/publication/ebmreg/","publishdate":"2020-08-22T00:00:00Z","relpermalink":"/publication/ebmreg/","section":"publication","summary":"ECCV 2020 A general method for accurate regression by learning the conditional target probability distribution as a deep energy-based model.","tags":null,"title":"Energy-Based Models for Deep Probabilistic Regression","type":"publication"},{"authors":["Xinkai Lu","Wenguan Wang","Martin Danelljan","Tianfei Zhou","Jianbing Shen","Luc Van Gool"],"categories":null,"content":"","date":1597968000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597968000,"objectID":"83986fa84387aec0debf253fdf9f7bbd","permalink":"https://martin-danelljan.github.io/publication/egmvos/","publishdate":"2020-08-21T00:00:00Z","relpermalink":"/publication/egmvos/","section":"publication","summary":"ECCV 2020 Spotlight\nA graph-based memory module for Video Object Segmentation.","tags":null,"title":"Video Object Segmentation with Episodic Graph Memory Networks","type":"publication"},{"authors":["Goutam Bhat","Martin Danelljan","Luc Van Gool","Radu Timofte"],"categories":null,"content":"","date":1597881600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597881600,"objectID":"d382eec104fbc108259aa59dd655f448","permalink":"https://martin-danelljan.github.io/publication/kys/","publishdate":"2020-08-20T00:00:00Z","relpermalink":"/publication/kys/","section":"publication","summary":"ECCV 2020 A tracking architecture that exploits the knowledge about the presence of other objects in the surrounding scene to prevent failure.","tags":null,"title":"Know Your Surroundings: Exploiting Scene Information for Object Tracking","type":"publication"},{"authors":["Prune Truong","Martin Danelljan","Radu Timofte"],"categories":null,"content":"","date":1592697600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592697600,"objectID":"71ea4fd8fa805e4afc3cacba5ef09ad9","permalink":"https://martin-danelljan.github.io/publication/glunet/","publishdate":"2020-06-21T00:00:00Z","relpermalink":"/publication/glunet/","section":"publication","summary":"CVPR 2020 Oral\nA unified network architecture for dense correspondences applicable to geometric matching, optical flow and semantic matching.","tags":null,"title":"GLU-Net: Global-Local Universal Network for Dense Flow and Correspondences","type":"publication"},{"authors":["Andreas Robinson","Felix Järemo Lawin","Martin Danelljan","Fahad Shahbaz Khan","Michael Felsberg"],"categories":null,"content":"","date":1592611200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592611200,"objectID":"c880a3a34f65a8219978555e73973cdc","permalink":"https://martin-danelljan.github.io/publication/frtm/","publishdate":"2020-06-20T00:00:00Z","relpermalink":"/publication/frtm/","section":"publication","summary":"CVPR 2020 Oral\nA light-weight optimization-based target model for fast VOS.","tags":null,"title":"Learning Fast and Robust Target Models for Video Object Segmentation","type":"publication"},{"authors":["Martin Danelljan","Luc Van Gool","Radu Timofte"],"categories":null,"content":"","date":1592524800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592524800,"objectID":"7a487f07ffdc95c72422666f1b14b860","permalink":"https://martin-danelljan.github.io/publication/prdimp/","publishdate":"2020-06-19T00:00:00Z","relpermalink":"/publication/prdimp/","section":"publication","summary":"CVPR 2020 Proposes a general formulation for probabilistic regression, which is then applied to visual tracking.","tags":null,"title":"Probabilistic Regression for Visual Tracking","type":"publication"},{"authors":["Tiancai Wang","Tong Yang","Martin Danelljan","Fahad Shahbaz Khan","Xiangyu Zhang","Jian Sun"],"categories":null,"content":"","date":1592438400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592438400,"objectID":"50f30a630243b7db2a373c4e35eae5ff","permalink":"https://martin-danelljan.github.io/publication/iphoi/","publishdate":"2020-06-18T00:00:00Z","relpermalink":"/publication/iphoi/","section":"publication","summary":"CVPR 2020 A fully-convolutional approach that directly detects the interactions between human-object pairs.","tags":null,"title":"Learning Human-Object Interaction Detection using Interaction Points","type":"publication"},{"authors":["Goutam Bhat","Martin Danelljan","Luc Van Gool","Radu Timofte"],"categories":null,"content":"","date":1573344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573344000,"objectID":"8d262c5d247b374f3afa7ca2b693209b","permalink":"https://martin-danelljan.github.io/publication/dimp/","publishdate":"2019-11-10T00:00:00Z","relpermalink":"/publication/dimp/","section":"publication","summary":"ICCV 2019 Oral\nAn end-to-end tracking architecture, capable of fully exploiting both target and background appearance information for target model prediction.","tags":null,"title":"Learning Discriminative Model Prediction for Tracking","type":"publication"},{"authors":["Lichao Zhang","Abel Gonzalez-Garcia","Joost van de Weijer","Martin Danelljan","Fahad Shahbaz Khan"],"categories":null,"content":"","date":1573257600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573257600,"objectID":"21d85340db29052567a843dc7d441e4b","permalink":"https://martin-danelljan.github.io/publication/updatenet/","publishdate":"2019-11-09T00:00:00Z","relpermalink":"/publication/updatenet/","section":"publication","summary":"ICCV 2019 Replacing the handcrafted update function in Siamese trackers with a learnable update mechanism.","tags":null,"title":"Learning the Model Update for Siamese Trackers","type":"publication"},{"authors":null,"categories":null,"content":"Wowchemy is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you’ll find some examples of the types of technical content that can be rendered with Wowchemy.\nExamples Code Wowchemy supports a Markdown extension for highlighting code syntax. You can customize the styles under the syntax_highlighter option in your config/_default/params.yaml file.\n```python import pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() ``` renders as\nimport pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() Mindmaps Wowchemy supports a Markdown extension for mindmaps.\nSimply insert a Markdown markmap code block and optionally set the height of the mindmap as shown in the example below.\nA simple mindmap defined as a Markdown list:\n```markmap {height=\u0026#34;200px\u0026#34;} - Hugo Modules - wowchemy - wowchemy-plugins-netlify - wowchemy-plugins-netlify-cms - wowchemy-plugins-reveal ``` renders as\n- Hugo Modules - wowchemy - wowchemy-plugins-netlify - wowchemy-plugins-netlify-cms - wowchemy-plugins-reveal A more advanced mindmap with formatting, code blocks, and math:\n```markmap - Mindmaps - Links - [Wowchemy Docs](https://wowchemy.com/docs/) - [Discord Community](https://discord.gg/z8wNYzb) - [GitHub](https://github.com/wowchemy/wowchemy-hugo-themes) - Features - Markdown formatting - **inline** ~~text~~ *styles* - multiline text - `inline code` - ```js console.log(\u0026#39;hello\u0026#39;); console.log(\u0026#39;code block\u0026#39;); ``` - Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$ ``` renders as\n- Mindmaps - Links - [Wowchemy Docs](https://wowchemy.com/docs/) - [Discord Community](https://discord.gg/z8wNYzb) - [GitHub](https://github.com/wowchemy/wowchemy-hugo-themes) - Features - Markdown formatting - **inline** ~~text~~ *styles* - multiline text - `inline code` - ```js console.log(\u0026#39;hello\u0026#39;); console.log(\u0026#39;code block\u0026#39;); ``` - Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$ Charts Wowchemy supports the popular Plotly format for interactive charts.\nSave your Plotly JSON in your page folder, for example line-chart.json, and then add the {{\u0026lt; chart data=\u0026#34;line-chart\u0026#34; \u0026gt;}} shortcode where you would like the chart to appear.\nDemo:\nYou might also find the Plotly JSON Editor useful.\nMath Wowchemy supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.yaml file.\nTo render inline or block math, wrap your LaTeX math with {{\u0026lt; math \u0026gt;}}$...${{\u0026lt; /math \u0026gt;}} or {{\u0026lt; math \u0026gt;}}$$...$${{\u0026lt; /math \u0026gt;}}, respectively. (We wrap the LaTeX math in the Wowchemy math shortcode to prevent Hugo rendering our math as Markdown. The math shortcode is new in v5.5-dev.)\nExample math block:\n{{\u0026lt; math \u0026gt;}} $$ \\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2} $$ {{\u0026lt; /math \u0026gt;}} renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$ Example inline math {{\u0026lt; math \u0026gt;}}$\\nabla F(\\mathbf{x}_{n})${{\u0026lt; /math \u0026gt;}} renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the math linebreak (\\\\):\n{{\u0026lt; math \u0026gt;}} $$f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}$$ {{\u0026lt; /math \u0026gt;}} renders as\n$$ f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases} $$ Diagrams Wowchemy supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ``` renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ``` renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ``` renders …","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"https://martin-danelljan.github.io/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Wowchemy is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Markdown","type":"post"},{"authors":["Ardhendu Tripathi","Martin Danelljan","Luc Van Gool","Radu Timofte"],"categories":null,"content":"","date":1562716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562716800,"objectID":"ea6e3cedf02f3e89ba0b7b0c42c791d9","permalink":"https://martin-danelljan.github.io/publication/trknwn/","publishdate":"2019-07-10T00:00:00Z","relpermalink":"/publication/trknwn/","section":"publication","summary":"BMVC 2019 \"e propose a tracking framework that can exploit semantic information, without sacrificing the generic nature of the tracker.","tags":null,"title":"Tracking the Known and the Unknown by Leveraging Semantic Information","type":"publication"},{"authors":["Martin Danelljan","Goutam Bhat","Fahad Shahbaz Khan","Michael Felsberg"],"categories":null,"content":"","date":1561420800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561420800,"objectID":"ba6e114a997620cc26127c2a06d21048","permalink":"https://martin-danelljan.github.io/publication/atom/","publishdate":"2019-06-25T00:00:00Z","relpermalink":"/publication/atom/","section":"publication","summary":"CVPR 2019 Oral\nPerforming accurate bounding box estimation for generic visual tracking.","tags":null,"title":"ATOM: Accurate Tracking by Overlap Maximization","type":"publication"},{"authors":["Joakim Johnander","Martin Danelljan","Emil Brissman","Fahad Shahbaz Khan","Michael Felsberg"],"categories":null,"content":"","date":1561334400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561334400,"objectID":"d46a78103e030d74707cd1e7a606f291","permalink":"https://martin-danelljan.github.io/publication/agame/","publishdate":"2019-06-24T00:00:00Z","relpermalink":"/publication/agame/","section":"publication","summary":"CVPR 2019 Oral\nA generative appearance module for end-to-end VOS.","tags":null,"title":"A Generative Appearance Model for End-to-end Video Object Segmentation","type":"publication"},{"authors":["Martin Danelljan"],"categories":[],"content":"from IPython.core.display import Image Image(\u0026#39;https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png\u0026#39;) print(\u0026#34;Welcome to Academic!\u0026#34;) Welcome to Academic! Install Python and JupyterLab Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post\u0026#39;s title date: 2019-09-01 # Put any other Academic metadata here... --- Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post’s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=. Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"https://martin-danelljan.github.io/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://martin-danelljan.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Goutam Bhat","Joakim Johnander","Martin Danelljan","Fahad Shahbaz Khan","Michael Felsberg"],"categories":null,"content":"","date":1537833600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537833600,"objectID":"67668a87ff4b44c1534768402f43d243","permalink":"https://martin-danelljan.github.io/publication/updt/","publishdate":"2018-09-25T00:00:00Z","relpermalink":"/publication/updt/","section":"publication","summary":"ECCV 2019 How to better utilize deep features for correlation-based tracking.","tags":null,"title":"Unveiling the Power of Deep Tracking","type":"publication"},{"authors":["Felix Järemo Lawin","Martin Danelljan","Fahad Shahbaz Khan","Per-Erik Forssén","Michael Felsberg"],"categories":null,"content":"","date":1529452800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529452800,"objectID":"ade0749cc119bb715a7c13c10a0c69cc","permalink":"https://martin-danelljan.github.io/publication/dare/","publishdate":"2018-06-20T00:00:00Z","relpermalink":"/publication/dare/","section":"publication","summary":"CVPR 2018 Oral\nRevisiting the foundations of probabilistic point cloud registration in order to tackle the key issue of sampling density variations.","tags":null,"title":"Density Adaptive Point Set Registration","type":"publication"},{"authors":["Martin Danelljan","Goutam Bhat","Fahad Shahbaz Khan","Michael Felsberg"],"categories":null,"content":"","date":1500940800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1500940800,"objectID":"b2a5c708ed3323252426d03035de32c5","permalink":"https://martin-danelljan.github.io/publication/eco/","publishdate":"2017-07-25T00:00:00Z","relpermalink":"/publication/eco/","section":"publication","summary":"CVPR 2017 Tackling the key causes behind the problems of computational complexity and over-fitting in correlation trackers.","tags":null,"title":"ECO: Efficient Convolution Operators for Tracking","type":"publication"},{"authors":["Martin Danelljan","Andreas Robinson","Fahad Shahbaz Khan","Michael Felsberg"],"categories":null,"content":"","date":1475625600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475625600,"objectID":"0f3052d27383ed0a21301f52962cceeb","permalink":"https://martin-danelljan.github.io/publication/ccot/","publishdate":"2016-10-05T00:00:00Z","relpermalink":"/publication/ccot/","section":"publication","summary":"ECCV 2016 Oral\nA theoretical framework for discriminatively learning a convolution operator in the continuous spatial domain.","tags":null,"title":"Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking","type":"publication"},{"authors":["Martin Danelljan","Giulia Meneghetti","Fahad Shahbaz Khan","Michael Felsberg"],"categories":null,"content":"","date":1466812800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1466812800,"objectID":"e4ba4b76e728f77423bba8c90aa6f83d","permalink":"https://martin-danelljan.github.io/publication/cppsr/","publishdate":"2016-06-25T00:00:00Z","relpermalink":"/publication/cppsr/","section":"publication","summary":"CVPR 2016 A probabilistic point set registration framework that exploits available color information associated with the points.","tags":null,"title":"A Probabilistic Framework for Color-Based Point Set Registration","type":"publication"},{"authors":["Martin Danelljan","Gustav Häger","Fahad Shahbaz Khan","Michael Felsberg"],"categories":null,"content":"","date":1466726400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1466726400,"objectID":"6aa823a8b32a8ef597225e7c40da017a","permalink":"https://martin-danelljan.github.io/publication/decon/","publishdate":"2016-06-24T00:00:00Z","relpermalink":"/publication/decon/","section":"publication","summary":"CVPR 2016 A unified formulation for alleviating the problem of corrupted training samples in tracking-by-detection methods.","tags":null,"title":"Adaptive Decontamination of the Training Set: A Unified Formulation for Discriminative Visual Tracking","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://martin-danelljan.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":["Martin Danelljan","Gustav Häger","Fahad Shahbaz Khan","Michael Felsberg"],"categories":null,"content":"","date":1450137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1450137600,"objectID":"a592b69e09f0e337384a916e88aae516","permalink":"https://martin-danelljan.github.io/publication/srdcf/","publishdate":"2015-12-15T00:00:00Z","relpermalink":"/publication/srdcf/","section":"publication","summary":"ICCV 2015 Mitigating the unwanted boundary effects, which limits the performance of correlation based trackers.","tags":null,"title":"Learning Spatially Regularized Correlation Filters for Visual Tracking","type":"publication"},{"authors":["Martin Danelljan","Gustav Häger","Fahad Shahbaz Khan","Michael Felsberg"],"categories":null,"content":"","date":1410739200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1410739200,"objectID":"d398d100e12f43bf5b4939051e26edfe","permalink":"https://martin-danelljan.github.io/publication/dsst/","publishdate":"2014-09-15T00:00:00Z","relpermalink":"/publication/dsst/","section":"publication","summary":"TPAMI \u0026 BMVC 2014 Accurate and fast scale estimation for visual tracking.","tags":null,"title":"Discriminative Scale Space Tracking","type":"publication"},{"authors":["Martin Danelljan","Fahad Shahbaz Khan","Michael Felsberg","Joost van de Weijer"],"categories":null,"content":"","date":1403568000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1403568000,"objectID":"8ab3aacdd0ad0e9b6677eb084309269a","permalink":"https://martin-danelljan.github.io/publication/act/","publishdate":"2014-06-24T00:00:00Z","relpermalink":"/publication/act/","section":"publication","summary":"CVPR 2014 Oral\nHow to incorporate color information into visual tracking.","tags":null,"title":"Adaptive Color Attributes for Real-Time Visual Tracking","type":"publication"}]